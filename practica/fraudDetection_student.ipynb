{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: fraud detection through ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/fraud.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will use all the skills in ensemble learning we acquired from previous exercises to build a an automated fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed. Both correctness of the solution and code quality will be taken into account for marking.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary excercise that can help you gain a deeper knowledge into the topic. This exercise won't be taken into account towards marking, but you are encouraged to undertake it. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Ensembles environment files](https://github.com/albarji/teaching-environments-ensembles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Shift+Tab to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this problem is included in the *data* folder, with separate files for training and test data. Each file includes several unidentified explanatory features, together with an \"Amount\" feature and the target \"Class\". Fraudulent operations are marked as Class == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Load the training and test data into Pandas DataFrames with names <b>train</b> and <b>test</b>, respectively.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "1 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "2 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "3 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "4  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train = pd.read_csv('data/fraud_train.csv', sep = \",\", encoding= 'utf-8')\n",
    "Fraud_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.866364</td>\n",
       "      <td>2.346949</td>\n",
       "      <td>-4.053307</td>\n",
       "      <td>3.983359</td>\n",
       "      <td>-3.463186</td>\n",
       "      <td>-1.280953</td>\n",
       "      <td>-4.474764</td>\n",
       "      <td>1.216655</td>\n",
       "      <td>-2.309829</td>\n",
       "      <td>-5.515507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049732</td>\n",
       "      <td>0.475840</td>\n",
       "      <td>0.404480</td>\n",
       "      <td>0.282030</td>\n",
       "      <td>-0.506901</td>\n",
       "      <td>-0.371741</td>\n",
       "      <td>0.615257</td>\n",
       "      <td>0.803163</td>\n",
       "      <td>124.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.793667</td>\n",
       "      <td>3.418911</td>\n",
       "      <td>-5.074445</td>\n",
       "      <td>4.035987</td>\n",
       "      <td>-3.527875</td>\n",
       "      <td>-1.923242</td>\n",
       "      <td>-5.065981</td>\n",
       "      <td>1.996885</td>\n",
       "      <td>-3.097379</td>\n",
       "      <td>-6.447202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168618</td>\n",
       "      <td>0.289531</td>\n",
       "      <td>-0.371888</td>\n",
       "      <td>0.144761</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.197431</td>\n",
       "      <td>0.328672</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>99.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.140723</td>\n",
       "      <td>3.568751</td>\n",
       "      <td>-5.896245</td>\n",
       "      <td>4.164720</td>\n",
       "      <td>-4.091193</td>\n",
       "      <td>-1.989960</td>\n",
       "      <td>-5.472436</td>\n",
       "      <td>2.422821</td>\n",
       "      <td>-2.909735</td>\n",
       "      <td>-6.287803</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131130</td>\n",
       "      <td>0.118022</td>\n",
       "      <td>-0.332704</td>\n",
       "      <td>0.139941</td>\n",
       "      <td>0.324758</td>\n",
       "      <td>-0.180769</td>\n",
       "      <td>0.177810</td>\n",
       "      <td>0.661555</td>\n",
       "      <td>99.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.622469</td>\n",
       "      <td>3.480623</td>\n",
       "      <td>-6.200677</td>\n",
       "      <td>4.311234</td>\n",
       "      <td>-5.226286</td>\n",
       "      <td>-1.341764</td>\n",
       "      <td>-5.220941</td>\n",
       "      <td>2.682844</td>\n",
       "      <td>-2.921484</td>\n",
       "      <td>-6.561257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949569</td>\n",
       "      <td>-0.428986</td>\n",
       "      <td>-0.350676</td>\n",
       "      <td>0.197550</td>\n",
       "      <td>0.159234</td>\n",
       "      <td>-0.377791</td>\n",
       "      <td>-0.213562</td>\n",
       "      <td>0.459529</td>\n",
       "      <td>219.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.616293</td>\n",
       "      <td>3.563428</td>\n",
       "      <td>-7.058901</td>\n",
       "      <td>4.284346</td>\n",
       "      <td>-5.096299</td>\n",
       "      <td>-1.768618</td>\n",
       "      <td>-4.937554</td>\n",
       "      <td>2.748460</td>\n",
       "      <td>-3.796760</td>\n",
       "      <td>-6.825490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.215976</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>-1.059098</td>\n",
       "      <td>0.275662</td>\n",
       "      <td>0.057425</td>\n",
       "      <td>-0.265838</td>\n",
       "      <td>-0.514637</td>\n",
       "      <td>0.388590</td>\n",
       "      <td>254.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.866364  2.346949 -4.053307  3.983359 -3.463186 -1.280953 -4.474764   \n",
       "1 -4.793667  3.418911 -5.074445  4.035987 -3.527875 -1.923242 -5.065981   \n",
       "2 -5.140723  3.568751 -5.896245  4.164720 -4.091193 -1.989960 -5.472436   \n",
       "3 -5.622469  3.480623 -6.200677  4.311234 -5.226286 -1.341764 -5.220941   \n",
       "4 -6.616293  3.563428 -7.058901  4.284346 -5.096299 -1.768618 -4.937554   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.216655 -2.309829 -5.515507  ...  1.049732  0.475840  0.404480  0.282030   \n",
       "1  1.996885 -3.097379 -6.447202  ...  1.168618  0.289531 -0.371888  0.144761   \n",
       "2  2.422821 -2.909735 -6.287803  ...  1.131130  0.118022 -0.332704  0.139941   \n",
       "3  2.682844 -2.921484 -6.561257  ...  0.949569 -0.428986 -0.350676  0.197550   \n",
       "4  2.748460 -3.796760 -6.825490  ...  1.215976  0.041178 -1.059098  0.275662   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.506901 -0.371741  0.615257  0.803163  124.53      1  \n",
       "1  0.084735 -0.197431  0.328672  0.835395   99.85      1  \n",
       "2  0.324758 -0.180769  0.177810  0.661555   99.90      1  \n",
       "3  0.159234 -0.377791 -0.213562  0.459529  219.80      1  \n",
       "4  0.057425 -0.265838 -0.514637  0.388590  254.76      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_test = pd.read_csv('data/fraud_test.csv', sep = \",\", encoding= 'utf-8')\n",
    "Fraud_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Perform a brief analysis of the training data to answer the following questions: how many explanatory variables do you have? What is the distribution of classes?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos simple completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "      <td>5246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.539993</td>\n",
       "      <td>0.182329</td>\n",
       "      <td>0.302563</td>\n",
       "      <td>0.308565</td>\n",
       "      <td>-0.470484</td>\n",
       "      <td>-0.037538</td>\n",
       "      <td>-0.397722</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>-0.212005</td>\n",
       "      <td>-0.269800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>-0.132105</td>\n",
       "      <td>-0.051927</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.133937</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>93.582991</td>\n",
       "      <td>0.046893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.700370</td>\n",
       "      <td>2.111652</td>\n",
       "      <td>2.698561</td>\n",
       "      <td>1.715353</td>\n",
       "      <td>2.036673</td>\n",
       "      <td>1.411958</td>\n",
       "      <td>2.273415</td>\n",
       "      <td>2.027100</td>\n",
       "      <td>1.322918</td>\n",
       "      <td>1.863553</td>\n",
       "      <td>...</td>\n",
       "      <td>1.154418</td>\n",
       "      <td>0.696071</td>\n",
       "      <td>0.748970</td>\n",
       "      <td>0.583605</td>\n",
       "      <td>0.470548</td>\n",
       "      <td>0.491799</td>\n",
       "      <td>0.460188</td>\n",
       "      <td>0.350230</td>\n",
       "      <td>250.696936</td>\n",
       "      <td>0.211430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-34.591213</td>\n",
       "      <td>-44.639245</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-21.248752</td>\n",
       "      <td>-21.922811</td>\n",
       "      <td>-37.353443</td>\n",
       "      <td>-9.283925</td>\n",
       "      <td>-18.271168</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.815353</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-2.185457</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-1.345640</td>\n",
       "      <td>-7.144717</td>\n",
       "      <td>-8.364853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.160978</td>\n",
       "      <td>-0.556885</td>\n",
       "      <td>0.070103</td>\n",
       "      <td>-0.719923</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.734639</td>\n",
       "      <td>-0.673759</td>\n",
       "      <td>-0.137595</td>\n",
       "      <td>-0.803361</td>\n",
       "      <td>-0.566849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227437</td>\n",
       "      <td>-0.549349</td>\n",
       "      <td>-0.178857</td>\n",
       "      <td>-0.332102</td>\n",
       "      <td>-0.136150</td>\n",
       "      <td>-0.328017</td>\n",
       "      <td>-0.061094</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>5.102500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.341215</td>\n",
       "      <td>0.142323</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>0.214909</td>\n",
       "      <td>-0.360585</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>-0.100690</td>\n",
       "      <td>0.079762</td>\n",
       "      <td>-0.173325</td>\n",
       "      <td>-0.116838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053649</td>\n",
       "      <td>-0.103794</td>\n",
       "      <td>-0.045147</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.168982</td>\n",
       "      <td>-0.080875</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>22.190000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.157161</td>\n",
       "      <td>0.867764</td>\n",
       "      <td>1.357493</td>\n",
       "      <td>1.089141</td>\n",
       "      <td>0.211143</td>\n",
       "      <td>0.400486</td>\n",
       "      <td>0.395594</td>\n",
       "      <td>0.401846</td>\n",
       "      <td>0.454970</td>\n",
       "      <td>0.422938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126478</td>\n",
       "      <td>0.299756</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>0.402059</td>\n",
       "      <td>0.434307</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.102887</td>\n",
       "      <td>0.083911</td>\n",
       "      <td>81.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.618082</td>\n",
       "      <td>16.713389</td>\n",
       "      <td>3.971381</td>\n",
       "      <td>11.927512</td>\n",
       "      <td>31.457046</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>7.938980</td>\n",
       "      <td>11.519106</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>4.534454</td>\n",
       "      <td>5.303607</td>\n",
       "      <td>3.979637</td>\n",
       "      <td>2.208209</td>\n",
       "      <td>2.964300</td>\n",
       "      <td>4.444505</td>\n",
       "      <td>5.414028</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V1           V2           V3           V4           V5  \\\n",
       "count  5246.000000  5246.000000  5246.000000  5246.000000  5246.000000   \n",
       "mean     -0.539993     0.182329     0.302563     0.308565    -0.470484   \n",
       "std       2.700370     2.111652     2.698561     1.715353     2.036673   \n",
       "min     -34.591213   -44.639245   -31.103685    -5.519697   -32.092129   \n",
       "25%      -1.160978    -0.556885     0.070103    -0.719923    -0.999000   \n",
       "50%      -0.341215     0.142323     0.692239     0.214909    -0.360585   \n",
       "75%       1.157161     0.867764     1.357493     1.089141     0.211143   \n",
       "max       1.618082    16.713389     3.971381    11.927512    31.457046   \n",
       "\n",
       "                V6           V7           V8           V9          V10  ...  \\\n",
       "count  5246.000000  5246.000000  5246.000000  5246.000000  5246.000000  ...   \n",
       "mean     -0.037538    -0.397722     0.131348    -0.212005    -0.269800  ...   \n",
       "std       1.411958     2.273415     2.027100     1.322918     1.863553  ...   \n",
       "min     -21.248752   -21.922811   -37.353443    -9.283925   -18.271168  ...   \n",
       "25%      -0.734639    -0.673759    -0.137595    -0.803361    -0.566849  ...   \n",
       "50%      -0.226545    -0.100690     0.079762    -0.173325    -0.116838  ...   \n",
       "75%       0.400486     0.395594     0.401846     0.454970     0.422938  ...   \n",
       "max      21.393069    34.303177    20.007208     7.938980    11.519106  ...   \n",
       "\n",
       "               V21          V22          V23          V24          V25  \\\n",
       "count  5246.000000  5246.000000  5246.000000  5246.000000  5246.000000   \n",
       "mean      0.010017    -0.132105    -0.051927     0.010908     0.133937   \n",
       "std       1.154418     0.696071     0.748970     0.583605     0.470548   \n",
       "min     -12.815353    -8.887017   -26.751119    -2.185457    -7.495741   \n",
       "25%      -0.227437    -0.549349    -0.178857    -0.332102    -0.136150   \n",
       "50%      -0.053649    -0.103794    -0.045147     0.068361     0.168982   \n",
       "75%       0.126478     0.299756     0.087792     0.402059     0.434307   \n",
       "max      27.202839     4.534454     5.303607     3.979637     2.208209   \n",
       "\n",
       "               V26          V27          V28       Amount        Class  \n",
       "count  5246.000000  5246.000000  5246.000000  5246.000000  5246.000000  \n",
       "mean      0.019680     0.023637    -0.001524    93.582991     0.046893  \n",
       "std       0.491799     0.460188     0.350230   250.696936     0.211430  \n",
       "min      -1.345640    -7.144717    -8.364853     0.000000     0.000000  \n",
       "25%      -0.328017    -0.061094    -0.007941     5.102500     0.000000  \n",
       "50%      -0.080875     0.015344     0.023243    22.190000     0.000000  \n",
       "75%       0.289032     0.102887     0.083911    81.665000     0.000000  \n",
       "max       2.964300     4.444505     5.414028  7712.430000     1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las Ãºnicas columnas un poco mÃ¡s explicatrivas son la cantidad y la variable objetivo, las observamos de cerca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  , 529.  , 239.93, ...,  39.85, 295.9 ,  31.39])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Amount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00      315\n",
       "1.98       96\n",
       "0.89       86\n",
       "9.99       80\n",
       "15.00      70\n",
       "         ... \n",
       "170.74      1\n",
       "25.77       1\n",
       "69.21       1\n",
       "217.91      1\n",
       "60.50       1\n",
       "Name: Amount, Length: 2648, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1     246\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AquÃ­ es donde observamos el gran desbalanceo de los datos: solo 246 casos positivos de fraude frente a 5000 negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay NAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the performance of a fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent activities are usually prosecuted, therefore fraudsters need to be creative and come up constantly with new ways of performing fraud. Furthermore, frauds are scarce (fortunately), and so we have few positive class patterns available for training. This means the problem is highly unbalanced, which is a problem for training good models, but is also a problem for the model evaluation. \n",
    "\n",
    "Consider a dumb model that classifies all data as negative (non-fraud). We can simulate the predictions of this model by creating a predictions vector of all zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumbpreds = [0] * len(Fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531071292413267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Fraud_test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yo should have obtained a 95% of accuracy, because most of the patterns are indeed negative. But this would be totally useless as a fraud detector! Therefore, we need a better metric.\n",
    "\n",
    "One that works well for heavily unbalanced problems is the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), or AUC in short. In scikit-learn this metric is readily available, and we can test how this reveals the poor performance of this dumb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(Fraud_test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AUC of 50% means the model is no better than a random guess. We should aim to maximize this metric and attain a 100%, meaning all fraudulent patterns obtain higher scores than non-fraud patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now we have scarce positive data, it might make sense to start building an unsupervised fraud detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Using <b>only the training data</b>, create an Isolation Forest model for anomaly detection. You can use the number of positive patterns in the data to adjust the contamination ratio. Then measure the performance of the model on the test set, in terms of AUC score.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Note the roc_auc_score metric must receive <b>positive class probabilities</b>. It is not possible to obtain these probabilities from an IsolationForest model, but you can make use of its decision_function method to obtain normality scores (average tree depth), which can be negated to obtain positive class scores.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "1 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "2 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "3 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "4  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Fraud_train[Fraud_train.columns[:-1]].values\n",
    "ytrain = Fraud_train[Fraud_train.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Fraud_test[Fraud_test.columns[:-1]].values\n",
    "ytest = Fraud_test[Fraud_test.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.31222654e+00,  1.95199201e+00, -1.60985073e+00, ...,\n",
       "         2.61145003e-01, -1.43275875e-01,  0.00000000e+00],\n",
       "       [-3.04354062e+00, -3.15730712e+00,  1.08846278e+00, ...,\n",
       "        -2.52773123e-01,  3.57642252e-02,  5.29000000e+02],\n",
       "       [-2.30334957e+00,  1.75924746e+00, -3.59744743e-01, ...,\n",
       "         3.95659889e-02, -1.53028797e-01,  2.39930000e+02],\n",
       "       ...,\n",
       "       [-3.10660310e+00, -3.60127032e+00,  8.52922990e-01, ...,\n",
       "         2.54061971e-03, -3.86346116e-01,  2.95900000e+02],\n",
       "       [-1.08892915e+00,  1.17309797e+00,  1.05487094e+00, ...,\n",
       "         8.78928247e-02,  7.99399249e-02,  3.13900000e+01],\n",
       "       [-1.66752498e+00, -2.83333539e-01,  2.60902667e+00, ...,\n",
       "         4.05664000e-02, -1.25800471e-01,  3.38900000e+01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x20b7d694248>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "isoforest = IsolationForest(n_estimators=1000)\n",
    "isoforest.fit(Xtrain)\n",
    "sns.displot(isoforest.decision_function(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoretestmines(model, Xtest, ytest):\n",
    "    npositives = sum(ytest == 1)\n",
    "    scores = model.decision_function(Xtest)\n",
    "    sortedidx = [x[0] for x in sorted(enumerate(scores), key=lambda x: x[1])]\n",
    "    anomaliesidx = sortedidx[:npositives]\n",
    "    return sum(ytest[anomaliesidx] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoretestmines(isoforest, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = isoforest.predict(Xtest)\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([5000,  246], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ytest, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los ceros por menos unos porque la funciÃ³n isoforest devuelve menos uno en los casos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ytest = np.array([1 if a == 1 else -1 for a in ytest]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1855642276422764"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(new_ytest,positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Create a visualization showing the performance of this model over the test data. Suggestion: make use of the <a href=https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html>ROC plot portrayed in the scikit-learn docs</a>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = isoforest.fit(Xtrain, ytrain).decision_function(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = roc_curve(ytest,y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucz = auc(ytest,y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-24d76c4fab60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m plt.plot(zz, roc_aucz, color='darkorange',\n\u001b[1;32m----> 6\u001b[1;33m          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'navy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(zz, roc_aucz, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Let's check now whether we can improve the results using supervised models, that is, models that exploit the Class information available in the training data. Try <b>at least five</b> ensemble-based classification models, <b>using only the data in the training set</b>.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Some suggestions on the scikit-learn models you can use are: Random Forest, Extra Trees, AdaBoost, Gradient Boosting,  Bagging, Voting and Stacking. You can also use an XGBClassifier, also included in this environment.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Bonus points will we awarded for:\n",
    "     <ul>\n",
    "         <li>Trying more ensemble strategies beyond the minimum requirement of five.</li>\n",
    "         <li>Improving the AUC score of your best model as much as possible.</li>\n",
    "         <li>Trying <a href=https://catboost.ai/>CatBoost</a> and/or <a href=https://lightgbm.readthedocs.io/en/latest/>LightGBM</a>, other two popular ensemble methods. Note you will need to install these in your environment.</li>\n",
    "     </ul>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Now create a visualization showing the performance of your supervised models on the test set, together with the unsupervised model. Has the performance improved after making use of the Class data? Which model obtains the best AUC?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
