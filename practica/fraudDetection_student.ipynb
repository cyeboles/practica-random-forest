{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: fraud detection through ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/fraud.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will use all the skills in ensemble learning we acquired from previous exercises to build a an automated fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed. Both correctness of the solution and code quality will be taken into account for marking.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary excercise that can help you gain a deeper knowledge into the topic. This exercise won't be taken into account towards marking, but you are encouraged to undertake it. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Ensembles environment files](https://github.com/albarji/teaching-environments-ensembles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Shift+Tab to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this problem is included in the *data* folder, with separate files for training and test data. Each file includes several unidentified explanatory features, together with an \"Amount\" feature and the target \"Class\". Fraudulent operations are marked as Class == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Load the training and test data into Pandas DataFrames with names <b>train</b> and <b>test</b>, respectively.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "1 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "2 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "3 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "4  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train = pd.read_csv('data/fraud_train.csv', sep = \",\", encoding= 'utf-8')\n",
    "Fraud_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.866364</td>\n",
       "      <td>2.346949</td>\n",
       "      <td>-4.053307</td>\n",
       "      <td>3.983359</td>\n",
       "      <td>-3.463186</td>\n",
       "      <td>-1.280953</td>\n",
       "      <td>-4.474764</td>\n",
       "      <td>1.216655</td>\n",
       "      <td>-2.309829</td>\n",
       "      <td>-5.515507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049732</td>\n",
       "      <td>0.475840</td>\n",
       "      <td>0.404480</td>\n",
       "      <td>0.282030</td>\n",
       "      <td>-0.506901</td>\n",
       "      <td>-0.371741</td>\n",
       "      <td>0.615257</td>\n",
       "      <td>0.803163</td>\n",
       "      <td>124.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.793667</td>\n",
       "      <td>3.418911</td>\n",
       "      <td>-5.074445</td>\n",
       "      <td>4.035987</td>\n",
       "      <td>-3.527875</td>\n",
       "      <td>-1.923242</td>\n",
       "      <td>-5.065981</td>\n",
       "      <td>1.996885</td>\n",
       "      <td>-3.097379</td>\n",
       "      <td>-6.447202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168618</td>\n",
       "      <td>0.289531</td>\n",
       "      <td>-0.371888</td>\n",
       "      <td>0.144761</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.197431</td>\n",
       "      <td>0.328672</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>99.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.140723</td>\n",
       "      <td>3.568751</td>\n",
       "      <td>-5.896245</td>\n",
       "      <td>4.164720</td>\n",
       "      <td>-4.091193</td>\n",
       "      <td>-1.989960</td>\n",
       "      <td>-5.472436</td>\n",
       "      <td>2.422821</td>\n",
       "      <td>-2.909735</td>\n",
       "      <td>-6.287803</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131130</td>\n",
       "      <td>0.118022</td>\n",
       "      <td>-0.332704</td>\n",
       "      <td>0.139941</td>\n",
       "      <td>0.324758</td>\n",
       "      <td>-0.180769</td>\n",
       "      <td>0.177810</td>\n",
       "      <td>0.661555</td>\n",
       "      <td>99.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.622469</td>\n",
       "      <td>3.480623</td>\n",
       "      <td>-6.200677</td>\n",
       "      <td>4.311234</td>\n",
       "      <td>-5.226286</td>\n",
       "      <td>-1.341764</td>\n",
       "      <td>-5.220941</td>\n",
       "      <td>2.682844</td>\n",
       "      <td>-2.921484</td>\n",
       "      <td>-6.561257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949569</td>\n",
       "      <td>-0.428986</td>\n",
       "      <td>-0.350676</td>\n",
       "      <td>0.197550</td>\n",
       "      <td>0.159234</td>\n",
       "      <td>-0.377791</td>\n",
       "      <td>-0.213562</td>\n",
       "      <td>0.459529</td>\n",
       "      <td>219.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.616293</td>\n",
       "      <td>3.563428</td>\n",
       "      <td>-7.058901</td>\n",
       "      <td>4.284346</td>\n",
       "      <td>-5.096299</td>\n",
       "      <td>-1.768618</td>\n",
       "      <td>-4.937554</td>\n",
       "      <td>2.748460</td>\n",
       "      <td>-3.796760</td>\n",
       "      <td>-6.825490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.215976</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>-1.059098</td>\n",
       "      <td>0.275662</td>\n",
       "      <td>0.057425</td>\n",
       "      <td>-0.265838</td>\n",
       "      <td>-0.514637</td>\n",
       "      <td>0.388590</td>\n",
       "      <td>254.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.866364  2.346949 -4.053307  3.983359 -3.463186 -1.280953 -4.474764   \n",
       "1 -4.793667  3.418911 -5.074445  4.035987 -3.527875 -1.923242 -5.065981   \n",
       "2 -5.140723  3.568751 -5.896245  4.164720 -4.091193 -1.989960 -5.472436   \n",
       "3 -5.622469  3.480623 -6.200677  4.311234 -5.226286 -1.341764 -5.220941   \n",
       "4 -6.616293  3.563428 -7.058901  4.284346 -5.096299 -1.768618 -4.937554   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.216655 -2.309829 -5.515507  ...  1.049732  0.475840  0.404480  0.282030   \n",
       "1  1.996885 -3.097379 -6.447202  ...  1.168618  0.289531 -0.371888  0.144761   \n",
       "2  2.422821 -2.909735 -6.287803  ...  1.131130  0.118022 -0.332704  0.139941   \n",
       "3  2.682844 -2.921484 -6.561257  ...  0.949569 -0.428986 -0.350676  0.197550   \n",
       "4  2.748460 -3.796760 -6.825490  ...  1.215976  0.041178 -1.059098  0.275662   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.506901 -0.371741  0.615257  0.803163  124.53      1  \n",
       "1  0.084735 -0.197431  0.328672  0.835395   99.85      1  \n",
       "2  0.324758 -0.180769  0.177810  0.661555   99.90      1  \n",
       "3  0.159234 -0.377791 -0.213562  0.459529  219.80      1  \n",
       "4  0.057425 -0.265838 -0.514637  0.388590  254.76      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_test = pd.read_csv('data/fraud_test.csv', sep = \",\", encoding= 'utf-8')\n",
    "Fraud_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Perform a brief analysis of the training data to answer the following questions: how many explanatory variables do you have? What is the distribution of classes?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos simple completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.539993</td>\n",
       "      <td>2.700370</td>\n",
       "      <td>-34.591213</td>\n",
       "      <td>-1.160978</td>\n",
       "      <td>-0.341215</td>\n",
       "      <td>1.157161</td>\n",
       "      <td>1.618082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.182329</td>\n",
       "      <td>2.111652</td>\n",
       "      <td>-44.639245</td>\n",
       "      <td>-0.556885</td>\n",
       "      <td>0.142323</td>\n",
       "      <td>0.867764</td>\n",
       "      <td>16.713389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.302563</td>\n",
       "      <td>2.698561</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>0.070103</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>1.357493</td>\n",
       "      <td>3.971381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.308565</td>\n",
       "      <td>1.715353</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-0.719923</td>\n",
       "      <td>0.214909</td>\n",
       "      <td>1.089141</td>\n",
       "      <td>11.927512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.470484</td>\n",
       "      <td>2.036673</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.360585</td>\n",
       "      <td>0.211143</td>\n",
       "      <td>31.457046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.037538</td>\n",
       "      <td>1.411958</td>\n",
       "      <td>-21.248752</td>\n",
       "      <td>-0.734639</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>0.400486</td>\n",
       "      <td>21.393069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.397722</td>\n",
       "      <td>2.273415</td>\n",
       "      <td>-21.922811</td>\n",
       "      <td>-0.673759</td>\n",
       "      <td>-0.100690</td>\n",
       "      <td>0.395594</td>\n",
       "      <td>34.303177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>2.027100</td>\n",
       "      <td>-37.353443</td>\n",
       "      <td>-0.137595</td>\n",
       "      <td>0.079762</td>\n",
       "      <td>0.401846</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.212005</td>\n",
       "      <td>1.322918</td>\n",
       "      <td>-9.283925</td>\n",
       "      <td>-0.803361</td>\n",
       "      <td>-0.173325</td>\n",
       "      <td>0.454970</td>\n",
       "      <td>7.938980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.269800</td>\n",
       "      <td>1.863553</td>\n",
       "      <td>-18.271168</td>\n",
       "      <td>-0.566849</td>\n",
       "      <td>-0.116838</td>\n",
       "      <td>0.422938</td>\n",
       "      <td>11.519106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.382506</td>\n",
       "      <td>1.451640</td>\n",
       "      <td>-3.105965</td>\n",
       "      <td>-0.516554</td>\n",
       "      <td>0.174525</td>\n",
       "      <td>1.098321</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.278504</td>\n",
       "      <td>1.961484</td>\n",
       "      <td>-17.769143</td>\n",
       "      <td>-0.493480</td>\n",
       "      <td>0.108530</td>\n",
       "      <td>0.616860</td>\n",
       "      <td>4.197071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.023124</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>-4.008640</td>\n",
       "      <td>-0.693497</td>\n",
       "      <td>-0.035346</td>\n",
       "      <td>0.663843</td>\n",
       "      <td>3.601670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.316888</td>\n",
       "      <td>1.994539</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.410207</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.411847</td>\n",
       "      <td>7.187926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.226081</td>\n",
       "      <td>0.926475</td>\n",
       "      <td>-3.573749</td>\n",
       "      <td>-0.305332</td>\n",
       "      <td>0.329266</td>\n",
       "      <td>0.893828</td>\n",
       "      <td>4.803689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.239723</td>\n",
       "      <td>1.529881</td>\n",
       "      <td>-13.563273</td>\n",
       "      <td>-0.597658</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.502715</td>\n",
       "      <td>4.087802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.288279</td>\n",
       "      <td>2.388610</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.442638</td>\n",
       "      <td>-0.025765</td>\n",
       "      <td>0.426714</td>\n",
       "      <td>6.739384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.199761</td>\n",
       "      <td>1.174877</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.615199</td>\n",
       "      <td>-0.112646</td>\n",
       "      <td>0.390955</td>\n",
       "      <td>3.042493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.021410</td>\n",
       "      <td>0.876647</td>\n",
       "      <td>-3.602657</td>\n",
       "      <td>-0.493306</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.505054</td>\n",
       "      <td>5.228342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.054128</td>\n",
       "      <td>0.712131</td>\n",
       "      <td>-11.748689</td>\n",
       "      <td>-0.167872</td>\n",
       "      <td>-0.023263</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>6.993759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>1.154418</td>\n",
       "      <td>-12.815353</td>\n",
       "      <td>-0.227437</td>\n",
       "      <td>-0.053649</td>\n",
       "      <td>0.126478</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.132105</td>\n",
       "      <td>0.696071</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-0.549349</td>\n",
       "      <td>-0.103794</td>\n",
       "      <td>0.299756</td>\n",
       "      <td>4.534454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.051927</td>\n",
       "      <td>0.748970</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-0.178857</td>\n",
       "      <td>-0.045147</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>5.303607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.583605</td>\n",
       "      <td>-2.185457</td>\n",
       "      <td>-0.332102</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.402059</td>\n",
       "      <td>3.979637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.133937</td>\n",
       "      <td>0.470548</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-0.136150</td>\n",
       "      <td>0.168982</td>\n",
       "      <td>0.434307</td>\n",
       "      <td>2.208209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.491799</td>\n",
       "      <td>-1.345640</td>\n",
       "      <td>-0.328017</td>\n",
       "      <td>-0.080875</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>0.460188</td>\n",
       "      <td>-7.144717</td>\n",
       "      <td>-0.061094</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.102887</td>\n",
       "      <td>4.444505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.350230</td>\n",
       "      <td>-8.364853</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.083911</td>\n",
       "      <td>5.414028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>93.582991</td>\n",
       "      <td>250.696936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.102500</td>\n",
       "      <td>22.190000</td>\n",
       "      <td>81.665000</td>\n",
       "      <td>7712.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>5246.0</td>\n",
       "      <td>0.046893</td>\n",
       "      <td>0.211430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count       mean         std        min       25%        50%  \\\n",
       "V1      5246.0  -0.539993    2.700370 -34.591213 -1.160978  -0.341215   \n",
       "V2      5246.0   0.182329    2.111652 -44.639245 -0.556885   0.142323   \n",
       "V3      5246.0   0.302563    2.698561 -31.103685  0.070103   0.692239   \n",
       "V4      5246.0   0.308565    1.715353  -5.519697 -0.719923   0.214909   \n",
       "V5      5246.0  -0.470484    2.036673 -32.092129 -0.999000  -0.360585   \n",
       "V6      5246.0  -0.037538    1.411958 -21.248752 -0.734639  -0.226545   \n",
       "V7      5246.0  -0.397722    2.273415 -21.922811 -0.673759  -0.100690   \n",
       "V8      5246.0   0.131348    2.027100 -37.353443 -0.137595   0.079762   \n",
       "V9      5246.0  -0.212005    1.322918  -9.283925 -0.803361  -0.173325   \n",
       "V10     5246.0  -0.269800    1.863553 -18.271168 -0.566849  -0.116838   \n",
       "V11     5246.0   0.382506    1.451640  -3.105965 -0.516554   0.174525   \n",
       "V12     5246.0  -0.278504    1.961484 -17.769143 -0.493480   0.108530   \n",
       "V13     5246.0  -0.023124    0.998689  -4.008640 -0.693497  -0.035346   \n",
       "V14     5246.0  -0.316888    1.994539 -19.214325 -0.410207   0.012875   \n",
       "V15     5246.0   0.226081    0.926475  -3.573749 -0.305332   0.329266   \n",
       "V16     5246.0  -0.239723    1.529881 -13.563273 -0.597658   0.020949   \n",
       "V17     5246.0  -0.288279    2.388610 -25.162799 -0.442638  -0.025765   \n",
       "V18     5246.0  -0.199761    1.174877  -9.498746 -0.615199  -0.112646   \n",
       "V19     5246.0   0.021410    0.876647  -3.602657 -0.493306   0.005828   \n",
       "V20     5246.0   0.054128    0.712131 -11.748689 -0.167872  -0.023263   \n",
       "V21     5246.0   0.010017    1.154418 -12.815353 -0.227437  -0.053649   \n",
       "V22     5246.0  -0.132105    0.696071  -8.887017 -0.549349  -0.103794   \n",
       "V23     5246.0  -0.051927    0.748970 -26.751119 -0.178857  -0.045147   \n",
       "V24     5246.0   0.010908    0.583605  -2.185457 -0.332102   0.068361   \n",
       "V25     5246.0   0.133937    0.470548  -7.495741 -0.136150   0.168982   \n",
       "V26     5246.0   0.019680    0.491799  -1.345640 -0.328017  -0.080875   \n",
       "V27     5246.0   0.023637    0.460188  -7.144717 -0.061094   0.015344   \n",
       "V28     5246.0  -0.001524    0.350230  -8.364853 -0.007941   0.023243   \n",
       "Amount  5246.0  93.582991  250.696936   0.000000  5.102500  22.190000   \n",
       "Class   5246.0   0.046893    0.211430   0.000000  0.000000   0.000000   \n",
       "\n",
       "              75%          max  \n",
       "V1       1.157161     1.618082  \n",
       "V2       0.867764    16.713389  \n",
       "V3       1.357493     3.971381  \n",
       "V4       1.089141    11.927512  \n",
       "V5       0.211143    31.457046  \n",
       "V6       0.400486    21.393069  \n",
       "V7       0.395594    34.303177  \n",
       "V8       0.401846    20.007208  \n",
       "V9       0.454970     7.938980  \n",
       "V10      0.422938    11.519106  \n",
       "V11      1.098321    12.018913  \n",
       "V12      0.616860     4.197071  \n",
       "V13      0.663843     3.601670  \n",
       "V14      0.411847     7.187926  \n",
       "V15      0.893828     4.803689  \n",
       "V16      0.502715     4.087802  \n",
       "V17      0.426714     6.739384  \n",
       "V18      0.390955     3.042493  \n",
       "V19      0.505054     5.228342  \n",
       "V20      0.179043     6.993759  \n",
       "V21      0.126478    27.202839  \n",
       "V22      0.299756     4.534454  \n",
       "V23      0.087792     5.303607  \n",
       "V24      0.402059     3.979637  \n",
       "V25      0.434307     2.208209  \n",
       "V26      0.289032     2.964300  \n",
       "V27      0.102887     4.444505  \n",
       "V28      0.083911     5.414028  \n",
       "Amount  81.665000  7712.430000  \n",
       "Class    0.000000     1.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las Ãºnicas columnas un poco mÃ¡s explicatrivas son la cantidad y la variable objetivo, las observamos de cerca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  , 529.  , 239.93, ...,  39.85, 295.9 ,  31.39])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Amount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00      315\n",
       "1.98       96\n",
       "0.89       86\n",
       "9.99       80\n",
       "15.00      70\n",
       "         ... \n",
       "170.74      1\n",
       "25.77       1\n",
       "69.21       1\n",
       "217.91      1\n",
       "60.50       1\n",
       "Name: Amount, Length: 2648, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1     246\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AquÃ­ es donde observamos el gran desbalanceo de los datos: solo 246 casos positivos de fraude frente a 5000 negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay NAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the performance of a fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent activities are usually prosecuted, therefore fraudsters need to be creative and come up constantly with new ways of performing fraud. Furthermore, frauds are scarce (fortunately), and so we have few positive class patterns available for training. This means the problem is highly unbalanced, which is a problem for training good models, but is also a problem for the model evaluation. \n",
    "\n",
    "Consider a dumb model that classifies all data as negative (non-fraud). We can simulate the predictions of this model by creating a predictions vector of all zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumbpreds = [0] * len(Fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531071292413267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Fraud_test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yo should have obtained a 95% of accuracy, because most of the patterns are indeed negative. But this would be totally useless as a fraud detector! Therefore, we need a better metric.\n",
    "\n",
    "One that works well for heavily unbalanced problems is the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), or AUC in short. In scikit-learn this metric is readily available, and we can test how this reveals the poor performance of this dumb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(Fraud_test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AUC of 50% means the model is no better than a random guess. We should aim to maximize this metric and attain a 100%, meaning all fraudulent patterns obtain higher scores than non-fraud patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now we have scarce positive data, it might make sense to start building an unsupervised fraud detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Using <b>only the training data</b>, create an Isolation Forest model for anomaly detection. You can use the number of positive patterns in the data to adjust the contamination ratio. Then measure the performance of the model on the test set, in terms of AUC score.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Note the roc_auc_score metric must receive <b>positive class probabilities</b>. It is not possible to obtain these probabilities from an IsolationForest model, but you can make use of its decision_function method to obtain normality scores (average tree depth), which can be negated to obtain positive class scores.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.234235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>1.951992</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>3.019740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-1.609851</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>-4.304597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>3.997906</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>4.732795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>-0.522188</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>3.624201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-1.357746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>-2.537387</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>1.713445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>1.391657</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.496358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-1.282858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>-2.772272</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>-2.447469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>3.202033</td>\n",
       "      <td>-0.414575</td>\n",
       "      <td>2.032912</td>\n",
       "      <td>4.895844</td>\n",
       "      <td>2.101344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>-2.899907</td>\n",
       "      <td>-0.503141</td>\n",
       "      <td>-6.560124</td>\n",
       "      <td>-10.912819</td>\n",
       "      <td>-4.609628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.595222</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.184372</td>\n",
       "      <td>1.464378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-4.289254</td>\n",
       "      <td>-1.692029</td>\n",
       "      <td>-1.470102</td>\n",
       "      <td>-6.771097</td>\n",
       "      <td>-6.079337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.389724</td>\n",
       "      <td>2.000635</td>\n",
       "      <td>-0.698826</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>-0.339237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>-1.140747</td>\n",
       "      <td>0.666780</td>\n",
       "      <td>-2.282194</td>\n",
       "      <td>-7.358083</td>\n",
       "      <td>2.581851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-2.830056</td>\n",
       "      <td>0.599717</td>\n",
       "      <td>-4.781831</td>\n",
       "      <td>-12.598419</td>\n",
       "      <td>6.739384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>-0.016822</td>\n",
       "      <td>1.725321</td>\n",
       "      <td>-2.615665</td>\n",
       "      <td>-5.131549</td>\n",
       "      <td>3.042493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.416956</td>\n",
       "      <td>0.283345</td>\n",
       "      <td>-1.334441</td>\n",
       "      <td>0.308334</td>\n",
       "      <td>-2.721853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.126911</td>\n",
       "      <td>2.102339</td>\n",
       "      <td>-0.430022</td>\n",
       "      <td>-0.171608</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.517232</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>-0.379068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>-0.035049</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.704181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>-0.465211</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.656805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>0.320198</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>-1.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>1.488901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>0.177840</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>0.566797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>-0.010016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>0.146793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>239.930000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2          3         4\n",
       "V1     -2.312227   -3.043541   -2.303350  -4.397974  1.234235\n",
       "V2      1.951992   -3.157307    1.759247   1.358367  3.019740\n",
       "V3     -1.609851    1.088463   -0.359745  -2.592844 -4.304597\n",
       "V4      3.997906    2.288644    2.330243   2.679787  4.732795\n",
       "V5     -0.522188    1.359805   -0.821628  -1.128131  3.624201\n",
       "V6     -1.426545   -1.064823   -0.075788  -1.706536 -1.357746\n",
       "V7     -2.537387    0.325574    0.562320  -3.496197  1.713445\n",
       "V8      1.391657   -0.067794   -0.399147  -0.248778 -0.496358\n",
       "V9     -2.770089   -0.270953   -0.238253  -0.247768 -1.282858\n",
       "V10    -2.772272   -0.838587   -1.525412  -4.801637 -2.447469\n",
       "V11     3.202033   -0.414575    2.032912   4.895844  2.101344\n",
       "V12    -2.899907   -0.503141   -6.560124 -10.912819 -4.609628\n",
       "V13    -0.595222    0.676502    0.022937   0.184372  1.464378\n",
       "V14    -4.289254   -1.692029   -1.470102  -6.771097 -6.079337\n",
       "V15     0.389724    2.000635   -0.698826  -0.007326 -0.339237\n",
       "V16    -1.140747    0.666780   -2.282194  -7.358083  2.581851\n",
       "V17    -2.830056    0.599717   -4.781831 -12.598419  6.739384\n",
       "V18    -0.016822    1.725321   -2.615665  -5.131549  3.042493\n",
       "V19     0.416956    0.283345   -1.334441   0.308334 -2.721853\n",
       "V20     0.126911    2.102339   -0.430022  -0.171608  0.009061\n",
       "V21     0.517232    0.661696   -0.294166   0.573574 -0.379068\n",
       "V22    -0.035049    0.435477   -0.932391   0.176968 -0.704181\n",
       "V23    -0.465211    1.375966    0.172726  -0.436207 -0.656805\n",
       "V24     0.320198   -0.293803   -0.087330  -0.053502 -1.632653\n",
       "V25     0.044519    0.279798   -0.156114   0.252405  1.488901\n",
       "V26     0.177840   -0.145362   -0.542628  -0.657488  0.566797\n",
       "V27     0.261145   -0.252773    0.039566  -0.827136 -0.010016\n",
       "V28    -0.143276    0.035764   -0.153029   0.849573  0.146793\n",
       "Amount  0.000000  529.000000  239.930000  59.000000  1.000000\n",
       "Class   1.000000    1.000000    1.000000   1.000000  1.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fraud_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Fraud_train[Fraud_train.columns[:-1]].values\n",
    "ytrain = Fraud_train[Fraud_train.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Fraud_test[Fraud_test.columns[:-1]].values\n",
    "ytest = Fraud_test[Fraud_test.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.31222654e+00,  1.95199201e+00, -1.60985073e+00, ...,\n",
       "         2.61145003e-01, -1.43275875e-01,  0.00000000e+00],\n",
       "       [-3.04354062e+00, -3.15730712e+00,  1.08846278e+00, ...,\n",
       "        -2.52773123e-01,  3.57642252e-02,  5.29000000e+02],\n",
       "       [-2.30334957e+00,  1.75924746e+00, -3.59744743e-01, ...,\n",
       "         3.95659889e-02, -1.53028797e-01,  2.39930000e+02],\n",
       "       ...,\n",
       "       [-3.10660310e+00, -3.60127032e+00,  8.52922990e-01, ...,\n",
       "         2.54061971e-03, -3.86346116e-01,  2.95900000e+02],\n",
       "       [-1.08892915e+00,  1.17309797e+00,  1.05487094e+00, ...,\n",
       "         8.78928247e-02,  7.99399249e-02,  3.13900000e+01],\n",
       "       [-1.66752498e+00, -2.83333539e-01,  2.60902667e+00, ...,\n",
       "         4.05664000e-02, -1.25800471e-01,  3.38900000e+01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x20b7cbbf9c8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "isoforest = IsolationForest(n_estimators=1000, contamination = 0.0469)\n",
    "isoforest.fit(Xtrain)\n",
    "sns.displot(isoforest.decision_function(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoretestmines(model, Xtest, ytest):\n",
    "    npositives = sum(ytest == 1)\n",
    "    scores = isoforest.decision_function(Xtest)\n",
    "    sortedidx = [x[0] for x in sorted(enumerate(scores), key=lambda x: x[1])]\n",
    "    anomaliesidx = sortedidx[:npositives]\n",
    "    return sum(ytest[anomaliesidx] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoretestmines(isoforest, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = isoforest.predict(Xtest)\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([5000,  246], dtype=int64))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ytest, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los ceros por menos unos porque la funciÃ³n isoforest devuelve menos uno en los casos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ytest = np.array([1 if a == 1 else -1 for a in ytest]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433365853658537"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pclp = (-1)*isoforest.decision_function(Xtest)\n",
    "roc_auc_score(ytest,y_pred_pclp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Create a visualization showing the performance of this model over the test data. Suggestion: make use of the <a href=https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html>ROC plot portrayed in the scikit-learn docs</a>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = []\n",
    "tpr = []\n",
    "roc_auc = []\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(ytest, y_pred_pclp,pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Let's check now whether we can improve the results using supervised models, that is, models that exploit the Class information available in the training data. Try <b>at least five</b> ensemble-based classification models, <b>using only the data in the training set</b>.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Some suggestions on the scikit-learn models you can use are: Random Forest, Extra Trees, AdaBoost, Gradient Boosting,  Bagging, Voting and Stacking. You can also use an XGBClassifier, also included in this environment.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Bonus points will we awarded for:\n",
    "     <ul>\n",
    "         <li>Trying more ensemble strategies beyond the minimum requirement of five.</li>\n",
    "         <li>Improving the AUC score of your best model as much as possible.</li>\n",
    "         <li>Trying <a href=https://catboost.ai/>CatBoost</a> and/or <a href=https://lightgbm.readthedocs.io/en/latest/>LightGBM</a>, other two popular ensemble methods. Note you will need to install these in your environment.</li>\n",
    "     </ul>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ensembles-labs\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Anaconda3\\envs\\ensembles-labs\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Anaconda3\\envs\\ensembles-labs\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def trainscore(X, y, Xte, yte, estimator):\n",
    "    \"\"\"Trains an estimator and returns score over a test set\"\"\"\n",
    "    estimator.fit(X, y)\n",
    "    return estimator.score(Xte, yte) * 100\n",
    "\n",
    "def tune(X, y, Xte, yte, estimator, param_dist, n_iter_search, n_jobs):\n",
    "    \"\"\"Performs hyperparameter tuning over an estimator\"\"\"\n",
    "    search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=n_iter_search, n_jobs=n_jobs)\n",
    "    return trainscore(X, y, Xte, yte, search)\n",
    "\n",
    "ntrees = 50\n",
    "\n",
    "models = {\n",
    "    \"randomForest\": {\n",
    "        \"class\" : RandomForestClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            \"n_estimators\" : [ntrees],\n",
    "            \"max_depth\": [3, 5, 10, 15, 20, 25, 30, None],\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "            \"min_samples_split\": [2, 4, 8, 16, 32, 64],\n",
    "            \"min_samples_leaf\": [1, 2, 4, 8, 16, 32, 64],\n",
    "            \"bootstrap\": [True, False],\n",
    "            \"criterion\": [\"gini\", \"entropy\"]\n",
    "        }\n",
    "    },    \n",
    "    \"boosting\": {\n",
    "        \"class\" : AdaBoostClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            \"n_estimators\" : [ntrees],\n",
    "            \"learning_rate\": np.logspace(-5,0,12)\n",
    "        }\n",
    "    },  \n",
    "    \"gradientBoosting\": {\n",
    "        \"class\" : GradientBoostingClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            \"n_estimators\" : [ntrees],\n",
    "            \"loss\": [\"deviance\", \"exponential\"],\n",
    "            \"learning_rate\": np.logspace(-5,0,12),\n",
    "            \"max_depth\": [3, 5, 10, 15, 20, 25, 30, None],\n",
    "            \"min_samples_split\": [2, 4, 8, 16, 32, 64],\n",
    "            \"min_samples_leaf\": [1, 2, 4, 8, 16, 32, 64],\n",
    "            \"subsample\" : [0.1, 0.2, 0.5, 0.9, 1],\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "        }\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"class\" : XGBClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            'n_estimators': [ntrees],\n",
    "            'gamma' : [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "            'max_depth': [6, 9, 12],\n",
    "            'subsample': [0.5, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.5, 0.9, 1.0],\n",
    "            'reg_lambda' : [0, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"class\" : AdaBoostClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            'n_estimators': [ntrees],\n",
    "            \"learning_rate\": np.logspace(-5,0,12),\n",
    "        }\n",
    "    },\n",
    "    \"BaggingClassifier\": {\n",
    "        \"class\" : BaggingClassifier(),\n",
    "        \"param_dist\" : {\n",
    "            \"n_estimators\" : [ntrees],\n",
    "            \"max_features\": [5,10,15,20,25,28],\n",
    "            \"bootstrap\": [True, False],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "n_jobs = 7\n",
    "n_iter_search = 50\n",
    "\n",
    "accs = {\n",
    "  modelname :tune(\n",
    "            Xtrain, ytrain,\n",
    "            Xtest, ytest, \n",
    "            models[modelname][\"class\"], \n",
    "            param_dist=models[modelname][\"param_dist\"], \n",
    "            n_iter_search=n_iter_search, \n",
    "            n_jobs=n_jobs\n",
    "            )\n",
    "        for modelname in models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomForest': 99.19939001143729,\n",
       " 'boosting': 99.08501715592833,\n",
       " 'gradientBoosting': 99.00876858558902,\n",
       " 'xgb': 99.12314144109799,\n",
       " 'AdaBoost': 99.08501715592833,\n",
       " 'BaggingClassifier': 99.14220358368281}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Now create a visualization showing the performance of your supervised models on the test set, together with the unsupervised model. Has the performance improved after making use of the Class data? Which model obtains the best AUC?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='acc', ylabel='model'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resdf = pd.DataFrame({\n",
    "        \"dataset\" : \"fraud\",\n",
    "        \"model\" : [model for model in accs.keys()],\n",
    "        \"acc\" : [acc for acc in accs.values()]\n",
    "    })\n",
    "\n",
    "modelscores = resdf.groupby([\"model\"]).mean()[\"acc\"].sort_values()\n",
    "modelscores\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(y=\"model\", x=\"acc\", data=resdf, order=modelscores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
